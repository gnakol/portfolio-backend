# Configuration Prometheus pour Mission Control

## üéØ Objectif

Le Mission Control MCO affiche maintenant des m√©triques Kubernetes r√©cup√©r√©es depuis Prometheus :
- **Nombre de pods actifs** dans le namespace `portfolio`
- **RAM totale consomm√©e** par les pods

Ces donn√©es permettent de **valider la coh√©rence** entre les dashboards Grafana (technique) et Mission Control (business).

---

## üìã Pr√©requis

1. **Prometheus install√©** sur le cluster K8s
2. **Kube-state-metrics** install√© (pour exposer les m√©triques K8s)
3. **Port-forward SSH** ou acc√®s interne au service Prometheus

---

## ‚öôÔ∏è Configuration

### 1. **Local (d√©veloppement)**

Dans `application.yml` :

```yaml
prometheus:
  url: http://localhost:9090
```

Port-forward vers Prometheus (si n√©cessaire) :
```bash
kubectl port-forward -n monitoring svc/prometheus-server 9090:80
```

---

### 2. **Production (AWS K8s)**

#### Option A : Port-forward SSH (actuel)

Comme tu le fais d√©j√† pour Grafana, tu peux faire pareil pour Prometheus :

```bash
ssh -i ~/.ssh/portfolio-ci -L 9090:127.0.0.1:<PROMETHEUS_PORT> ubuntu@16.16.18.110
```

Puis dans `application-prod.yml` (ou variable d'environnement) :

```yaml
prometheus:
  url: http://localhost:9090
```

#### Option B : Service interne Kubernetes (recommand√©)

Si Prometheus est d√©ploy√© dans K8s, le pod `portfolio-api` peut l'interroger directement via le service K8s :

```yaml
prometheus:
  url: http://prometheus-server.monitoring.svc.cluster.local:80
```

Remplace `prometheus-server` et `monitoring` par le nom r√©el du service et du namespace Prometheus.

Pour v√©rifier :
```bash
kubectl get svc -n monitoring
```

#### Option C : Variable d'environnement

Dans ton d√©ploiement K8s (`portfolio-api-deployment.yaml`), ajoute :

```yaml
env:
  - name: PROMETHEUS_URL
    value: "http://prometheus-server.monitoring.svc.cluster.local:80"
```

---

## üîç Queries PromQL utilis√©es

### Nombre de pods actifs
```promql
count(kube_pod_info{namespace="portfolio",pod=~"portfolio.*|mysql.*|nginx.*"})
```

### RAM totale des pods (en bytes)
```promql
sum(container_memory_working_set_bytes{namespace="portfolio",container!="",container!="POD"})
```

---

## üß™ Tester les queries manuellement

1. Ouvre Grafana ou Prometheus UI
2. Va dans **Explore**
3. Copie-colle les queries ci-dessus
4. V√©rifie que tu obtiens des valeurs coh√©rentes

Exemple de r√©sultat attendu :
- **Pods count** : `4` (mysql, nginx, portfolio-api, portfolio-front)
- **RAM total** : ~1.2 GB (selon ta config)

---

## üìä Validation pour LinkedIn

Une fois configur√©, tu pourras faire la d√©mo :

1. **Ouvre Mission Control** : `https://kolie-portfolio.org/mission-control`
2. **Note les valeurs** :
   - Pods actifs : `4`
   - RAM totale : `1.2 GB`
3. **Clique sur "Grafana"**
4. **Montre les m√™mes m√©triques** dans Grafana avec les queries PromQL
5. **Message cl√©** : "M√™me source de donn√©es (Prometheus), deux interfaces : technique (Grafana) vs business (MCO)"

---

## üöÄ D√©ploiement

1. Build le backend :
   ```bash
   cd portfolio-api
   mvn clean package -DskipTests
   ```

2. Build le frontend :
   ```bash
   cd portfolio-template
   npm run build
   ```

3. Deploy sur AWS (via ton pipeline CI/CD)

4. V√©rifie les logs du pod `portfolio-api` :
   ```bash
   kubectl logs -f deployment/portfolio-api -n portfolio
   ```

   Cherche les logs :
   ```
   ‚úÖ Prometheus query successful: podsCount=4
   ‚úÖ Prometheus query successful: totalRamBytes=1234567890
   ```

   Ou les erreurs :
   ```
   ‚ùå Error querying Prometheus: Connection refused
   ```

---

## üêõ Troubleshooting

### Erreur : "Connection refused"

**Cause** : Le backend ne peut pas joindre Prometheus √† l'URL configur√©e.

**Solutions** :
1. V√©rifie que Prometheus est accessible :
   ```bash
   curl http://localhost:9090/api/v1/query?query=up
   ```

2. V√©rifie la variable `prometheus.url` dans les logs :
   ```bash
   kubectl logs deployment/portfolio-api -n portfolio | grep prometheus
   ```

3. Teste depuis le pod :
   ```bash
   kubectl exec -it deployment/portfolio-api -n portfolio -- curl http://prometheus-server.monitoring.svc.cluster.local/api/v1/query?query=up
   ```

### M√©triques √† z√©ro (0 pods, 0 GB)

**Cause** : Les queries PromQL ne retournent aucun r√©sultat.

**Solutions** :
1. V√©rifie que `kube-state-metrics` est install√© :
   ```bash
   kubectl get pods -n kube-system | grep kube-state-metrics
   ```

2. Teste les queries directement dans Prometheus UI

3. Ajuste les regex dans les queries (namespace, noms de pods)

---

## üìù Notes

- Le service Prometheus interroge l'API toutes les fois que le MCO est ouvert (pas de cache pour l'instant)
- Timeout : 5 secondes par requ√™te
- En cas d'erreur, les valeurs affichent `-` ou `0`
- Les logs d'erreur sont visibles dans les logs du backend (niveau `ERROR`)

---

## ‚úÖ Checklist de validation

- [ ] Prometheus accessible depuis le backend
- [ ] Query pods count retourne `4`
- [ ] Query RAM retourne ~1.2 GB
- [ ] Mission Control affiche les valeurs correctes
- [ ] Grafana confirme les m√™mes valeurs
- [ ] Pr√™t pour la d√©mo LinkedIn üé¨
